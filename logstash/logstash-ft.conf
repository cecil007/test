input {
	file {
		path => "/mnt/ufo_logs/track_*"
		type => "track"
	}

	file {
		path => "/mnt/ufo_logs/internal_track_*"
		type => "internal"
	}

	file {
		path => "/mnt/ufo_logs/sys_*"
		type => "sys"
	}

	file {
		path => "/mnt/ufo_logs/else/**/*"
		type => "else"
	}
}


filter {
	if [type] in ["track", "internal"] {
		multiline {
			pattern => "\[\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2},\d{3}\].*"
			negate => true
			what => "previous"
		}
	}
}

filter {

	# env
	mutate {
		add_field => {
			"_env" => "ft"
		}
	}

	if [type] in ["track", "internal"]
	{
		grok {
			#break_on_match => false
	                #keep_empty_captures => true
			match => {"message" => "\[%{DATETIME:tmp_timestamp}\].*RequestHeader:%{SOMETHING:RequestHeader}\n.*RequestBody:%{SOMETHING:RequestBody}\n(.*ErrorStack:%{ANYTHING:ErrorStack}\n\[\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2},\d{3}\])*.*ResponseMsg:%{SOMETHING:ResponseMsg}\n.*HTTPResult:%{ANYTHING:HTTPResult}%{AFTER:after}"}
		}
		grok {
			match => {"HTTPResult" => "%{NUMBER:status} %{WORD:method} %{URIPATH:uri}(:?%{URIPARAM:uri_param})? \(%{IP:server}\) %{NUMBER:duration}ms"}
		}

		# json解析
		json {
			source => "RequestHeader"
			target => "tmpRequestHeader"
		}


		json {
			source => "RequestBody"
			target => "Body"
		}

		json {
			source => "ResponseMsg"
			target => "tmpResponseMsg"
		}

		# 字段处理
		# 时间格式处理
		date {
			match => [ "tmp_timestamp" , "yyyy-MM-dd HH:mm:ss,SSS" ]
	#		timezone => "UTC"
		}

		if [ErrorStack]
		{
			mutate {
				add_field => {
					"has_error" => true
				}
			}
		} else {
			mutate {
				add_field => {
					"has_error" => false
				}
			}
		}


		mutate {
			add_field => {
				"platform" => "%{Body[common][platform]}"
				"version" => "%{Body[common][version]}"
			}
		}

		if "Cmdid" in [tmpRequestHeader] {
			mutate {
				add_field => {
					"cmdid" => "%{tmpRequestHeader[Cmdid]}"
				}
			}
		} else {
			mutate {
				add_field => {
					"cmdid" => "%{tmpRequestHeader[cmdid]}"
				}
			}
		}


		mutate {
			
			add_field => {
#				"cmdid" => "%{tmpRequestHeader[Cmdid]}"
				"userid" => "%{tmpResponseMsg[common][userid]}"
				"code" => "%{tmpResponseMsg[common][code]}"
			}
			remove_field => ["tmpRequestHeader", "tmpResponseMsg", "tmp_timestamp"]
			convert => {
				"duration" => "float"
				"status" => "integer"
				"cmdid" => "integer"
				"userid" => "integer"
				"platform" => "integer"
				"has_error" => "boolean"
				"code" => "integer"
			}
		}
	}
}

output {

        elasticsearch {
                hosts => ["192.168.10.10", "192.168.10.11", "192.168.10.12", "192.168.10.13", "192.168.10.14"]
                index => "logstash-%{_env}-%{type}-%{+YYYY.MM.dd}"
        }

#	elasticsearch {
#		hosts => ["192.168.10.51"]
#		index => "logstash-%{_env}-%{type}-%{+YYYY.MM.dd}"
#	}
#	stdout { codec => rubydebug }
#	kafka {
#                bootstrap_servers => "192.168.10.51:6667"
#                topic_id => "logstash-%{_env}"
#        }
#	redis {
#		host => "192.168.0.8"
##		password => ""
#		db => 10
#		data_type => "channel"
#		key => "logstash"
#	}
}
